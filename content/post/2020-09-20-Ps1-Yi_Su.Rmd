---
title: "Positive correlation between severity of fire incident, estimated loss and number of responding firefighters"
author: "Yi Su"
date: 2020-09-17
abstract: "This post analyzed the impact of severity of fire incidents on both economic loss and the number of firefighter responded. As well as correlation between loss and number of firefighters just for demonstration of the role of severity of fire between them"
output:
  html_document:
    df_print: paged
---
> # Abstract
> This post analyzed the impact of severity of fire incidents on both economic loss and the number of firefighter responded. As well as correlation between loss and number of firefighters just for demonstration of the role of severity of fire between them

# Introduction
  "Fire Incidents Data" is a dataset published by the TFS, Toronto Fire Services containing 17536 observations of fire incidents defined by the Ontario Fire Marshal. For each observation, detailed assessments of the incident are recorded, such as crew arrival time, estimated loss in dollars, existence and type of fire alarm, number of casualties and more. 
  
  In this post, the distribution of estimated dollar loss caused by fire incidents, number of firefighters that responded to the incident, and the severity of fire incident will be examined. These variables should be in a positive correlation of each other theoratically, but the degree is arguable. The reason being more severe fire incidents required more firefighters in response and causes more loss in general, on the other hand, more firefighters involved should have better controll of the incident there fore result in smaller loss.

```{r,echo = FALSE,options(readr.num_columns = 0), message = FALSE}
library(tidyverse)
library(visdat)
RAW <- read_csv("Fire Incidents Data.csv")%>%select(Estimated_Dollar_Loss, Number_of_responding_personnel, Extent_Of_Fire )
#to build a data fram with only the varaiables we are interested in
Loss_NumUnit <- na.omit(RAW)
#to remove all the rows with NAs
Loss_NumUnit$Extent_Of_Fire <- as.numeric(sapply(strsplit(Loss_NumUnit$Extent_Of_Fire, " "), "[[", 1))
#since the TFS added a description fo fire severity at the end of it's numeric level, we only capture the numeric level by spliting the first character of the string which is the number
```

#Working on the Dataset
| To work with the Fire_Incidents dataset, we need to pull out the data we are interested in and make it tidy for graphing and regression. This could be done by simply selecting the variables we are interested in and removing all the empty observations (the NAs) of those variables. The three discrete variable we are intereted in are named "Estimated_Dollar_Loss", "Number_of_responding_personnel", and "Extent_Of_Fire" (severity) in the dataset, and this new dataset of three variables act as the observational data. In order to do this, the R package "tidyverse" was used.


| During the tidying, 6322 incidents were removed for having no value recorded, and those NAs are mostly from "Extent_of_Fire" variable. Another interesting feature of this dataset is that the "Extent_of_Fire" variable included a description of the level of severity in each incident. Severity is a bit different from the others as it is ranked from 1 to 10, 1 being the fire is confined to the object of origin, 10 being the fire spreaded beyond the building of origin. This is useful when interpreting the data, but not so tidy and convenient when graphing it. Therefore, we deleted all the description by taking advantage of the fact that all entry begin with the numeric level of severity. 


| To make the graph more readable, a couple outlier incidents that resulted in more than 6 million dollar estimated loss and required more than 1000 were removed. This should make the graphs to a significantly smaller scale, and therefore more readable. In addition, there exist a special value of 99 in "extent_of_fire". The 99 stands for severity undetermined, which only appeared 91 among the entire dataset. This special case is also considered as a NA value and therefore filtered out of our data.

#Individual Distribution

```{r, echo= FALSE,message = FALSE,fig.show="hold", out.width="80%"}
Loss_NumUnit_low <- Loss_NumUnit%>%
  filter(Estimated_Dollar_Loss < 6000000)%>%
  filter(Number_of_responding_personnel < 1000)%>%
  filter(Extent_Of_Fire < 90)
#to adjust the axis values by removing the 1 case that have significantly large estimated dollar loss and number of responding personnel. Also, there exist a severity of 99 in the extent of fire column which stands for undetermined, for accuracy, we remove it like a NA row.
Loss_NumUnit_low%>%
  ggplot(aes(x=Number_of_responding_personnel))+
  geom_histogram(binwidth = 10)+
  labs(x = "Number of Responding Personnel", y = "Count", title = "Fig.1, Distribution of Number of Responding Personnel")+
  theme(title = element_text(size = 15, face = "bold"),axis.title=element_text(size=12))
#clearly most fire incidents required less than 150 personnel
```

The individual distribution of each variable are displayed as above. For all three variables, the distributions are heavily centered at the left-most end of the graph. In more statistical words, they are all heavily right-skewed.
  
Looking at fig.1, Notice that the number of 4 personnels appeared a lot, this is because TFS assigns 4 firefighter and 1 fire truck as a unit in most cases. Using that, it is clear that fire incidents with lower severity should appear most often.

```{r,echo= FALSE,message = FALSE,fig.show="hold", out.width="80%"}
Loss_NumUnit_low%>%
  ggplot(aes(x=Estimated_Dollar_Loss))+
  geom_histogram()+
  labs(x = "Estimated Dollar Loss", y = "Count", title = "Fig.2, Distribution of Estimated Dollar Loss")+
  theme(title = element_text(size = 15, face = "bold"),axis.title=element_text(size=12))
#most losses are contained within $500,000
```
  
In fig.2, the majority of estimated loss in dollar are confined under $300,000. This is very intuitive, not all fire incidents results in a significant loss, only if the whole building was burned down or the area spread beyond the district.

```{r,echo= FALSE,message = FALSE,fig.show="hold", out.width="80%"}
Loss_NumUnit_low%>%
  ggplot(aes(x=Extent_Of_Fire))+
  geom_histogram(binwidth = 1)+
  labs(x = "Extent of Fire", y = "Count", title = "Fig.3, Distribution of Extent of Fire")+
  theme(title = element_text(size = 15, face = "bold"),axis.title=element_text(size=12))
#most fire incidents are restricted to less than 7-8
```

From distribution of "extent of fire", we see most incidents have a severity of less than 4, meaning it spreaded beyond room of origin but still at the same floor. Agian, this follows the intuition of most fire incidents are not severe.
  
#Are they Correlated?

To assess correlation, the use of simple linear regression model and hypothesis testing on correlation coefficients was done for each set of graphs. The regression model shows a direct graphical implication of the relationship and provides the correlation coefficient. The hypothesis testing is just an extra safe to show that correlation is not zero, so we used a null hypothesis of correlation coefficient equal to zero and the alternative being non-zero.


```{r,echo = FALSE, message = FALSE,fig.show="hold",out.width="50%"}
Loss_NumUnit_low%>%
  ggplot(aes(x=Extent_Of_Fire, y=Number_of_responding_personnel))+
  geom_point()+
  geom_smooth(method ="lm")+
  labs(x = "Extent of Fire", y = "Number of Responding Personnel", title = "Fig.4, Extent of Fire Vs. Number of Firefighters")+
  annotate("text", x = 4, y = 200,
  label = "paste(italic(R), \" = .431\")", parse = TRUE, size = 8)+
  annotate("text", x = 4, y = 300,
  label = "paste(italic(P-value), \" < 2.2e-16\")", parse = TRUE,size = 8)+
  theme(title = element_text(size = 15, face = "bold"),axis.title=element_text(size=12))
cor.test(Loss_NumUnit_low$Extent_Of_Fire,Loss_NumUnit_low$Number_of_responding_personnel)

Loss_NumUnit_low%>%
  ggplot(aes(x=Extent_Of_Fire, y=Estimated_Dollar_Loss))+
  geom_point()+
  geom_smooth(method ="lm")+
  labs(x = "Extent of Fire", y = "Estimated Dollar Loss", title = "Fig.5, Extent of Fire Vs. Dollar Loss")+
  annotate("text", x = 4, y = 1500000,
  label = "paste(italic(R), \" = .312\")", parse = TRUE,size = 8)+
  annotate("text", x = 4, y = 2500000,
  label = "paste(italic(P-value), \" < 2.2e-16\")", parse = TRUE,size = 8)+
  theme(title = element_text(size = 15, face = "bold"),axis.title=element_text(size=12))
cor.test(Loss_NumUnit_low$Extent_Of_Fire,Loss_NumUnit_low$Estimated_Dollar_Loss)

```

First, "Extent_of_fire" appears to have a positive relationship with both "Number_of_responding_personnel" and "Estimated_Dollar_Loss". The blue line in the graph is a simple linear regression line showing a positive correlation between the two variables for all three graphs, and the p-values both being so small is just an indication that we can be sure there exist some correlation between the variables.The R value (correlation coefficient) indicates the strength of relationship. Notice that the correlation coefficitn of 0.431 and 0.312 are considered as fairly weak, this is due to the fact that, there are always more elements other than severity of the incident which influences number of responding firefighters and estimated loss. For example, the number of firefighters in a certain responding area is limited in the given time, and maybe the incident happened in an area or building with less valuable item in dollars.

```{r,echo = FALSE, message = FALSE,fig.show="hold",out.width="80%"}
Loss_NumUnit_low%>%
  ggplot(aes(x=Estimated_Dollar_Loss, y=Number_of_responding_personnel))+
  geom_point()+
  geom_smooth(method ="lm")+
  labs(x = "Estimated Dollar Loss", y = "Number of Responding Personnel", title = "Fig.6, Dollar Loss Vs. Number of Firefighters")+
  annotate("text", x = 3000000, y = 400,
  label = "paste(italic(R), \" = .549\")", parse = TRUE,size = 8)+
  annotate("text", x = 3000000, y = 500,
  label = "paste(italic(P-value), \" < 2.2e-16\")", parse = TRUE,size = 8)+
  theme(title = element_text(size = 15, face = "bold"),axis.title=element_text(size=12))
cor.test(Loss_NumUnit_low$Estimated_Dollar_Loss,Loss_NumUnit_low$Number_of_responding_personnel)
```


Next, Looking at the impact of "Number_of_Responding_Personnel" on "Estimated_Dollar_Loss". The figure above shows that most incidents are clustered at the left-bottom corner, which follows our observation on the individual distribution of there two. Again, the small p-value shows the existence of some kind of correlation. A R value of 0. 549 appears that the correlation between number of firefighters involved and estimated dollar loss is stronger than the previous two. However, this does not mean there exist a causality of "more firefighters result in more loss" or the opposite, the more important rule is the severity of incident. "Extent_of_Fire" acts like a gear between them, linking higher estimated loss with more firefighter involved in average.
  
#Constraints of the data

The Fire Incidents dataset by TFS is a very detailed dataset but constraints still exist.The most obvious but unimportant one is the number of empty entries across the variables due to privacy protection. Beside that, there is no explanation on when is the extent of fire assessed, eventhough it shouldn't make a significant impact on the correlation coefficients, but it becomes a major issue when identifying the possible causality between the variables. In the case of after the incident is stablized, it becomes a more important influencer of loss in dollars. In the case of before, it is more important for number of responding personnels.

#Conclusion 

In conclusion, the extent of fire appears to be indeed one of the factor when assessing number of responding personnel and estimating loss in dollars. However, according to the strength of correlation coefficient, extent of fire may not be the main cause for those responding variables to be high. For example, longer fire-extinguish time may give TFS incentive to add the number of responding personnels, and more dangerous location of the incident like gas station may requrie more personnels and equipments to handle. There are more variables in the original dataset that could be potential factors, which could be worth the exploration of future works.

#Citations

* Toronto Fire Services (2020), Fire Incidents, Open Data Toronto. URL https://open.toronto.ca/dataset/fire-incidents/

* R Core Team (2020). R: A language and environment for statistical
  computing. R Foundation for Statistical Computing, Vienna,
  Austria. URL https://www.R-project.org/.

* Wickham et al., (2019). Welcome to the tidyverse. Journal of Open
  Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686

* H. Wickham. ggplot2: Elegant Graphics for Data Analysis.
  Springer-Verlag New York, 2016.

* Yihui Xie (2020). knitr: A General-Purpose Package for Dynamic
  Report Generation in R. R package version 1.29.

  + Yihui Xie (2015) Dynamic Documents with R and knitr. 2nd edition.
  Chapman and Hall/CRC. ISBN 978-1498716963

  + Yihui Xie (2014) knitr: A Comprehensive Tool for Reproducible
  Research in R. In Victoria Stodden, Friedrich Leisch and Roger D.
  Peng, editors, Implementing Reproducible Computational Research.
  Chapman and Hall/CRC. ISBN 978-1466561595

* Hadley Wickham, Romain François, Lionel Henry and Kirill Müller
  (2020). dplyr: A Grammar of Data Manipulation. R package version
  1.0.2. https://CRAN.R-project.org/package=dplyr

